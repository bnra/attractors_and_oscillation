{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attractors and Oscillation\n",
    "- running simulations\n",
    "- analyzing data\n",
    "- plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, \"..\")\n",
    "import numpy as np\n",
    "import tqdm\n",
    "\n",
    "import experiments_eif\n",
    "import ExperimentAnalysis\n",
    "import analysis\n",
    "import persistence \n",
    "import utils\n",
    "import mp\n",
    "import attractor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adapt this to the desired path where the simulation is tb saved\n",
    "# ensure sufficient disk space\n",
    "base_path = \"/media/ben/fbe4ea39-a83a-4758-9ccf-506225bbc38d/bla/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## run simulations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### single simulations (from python)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path_code = os.path.join(base_path, \"code\")\n",
    "fname = \"my_experiment.h5\"\n",
    "fnameu = \"my_experiment_unweighted.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "simtime = 2250.0\n",
    "rpe = 3.9\n",
    "rpi = 5.15\n",
    "esize = 4000\n",
    "sparsity = 0.05 \n",
    "stimuluspatternidx = 0\n",
    "perturbation = 0.0\n",
    "beta = 0.5\n",
    "minusbeta = 1.0\n",
    "continuousstim = False\n",
    "weighted = True\n",
    "norm = 4.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate patterns\n",
    "pattern = experiments_eif.generate_fixed_patterns(\n",
    "    esize=esize, sparsity=sparsity, numpatterns=20\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sim in [fname, fnameu]:\n",
    "    experiments_eif.run_exp_eif_attr_blocked_stimulus(simtime, os.path.join(base_path_code,sim), rpe, rpi, esize, sparsity, pattern, stimuluspatternidx, perturbation, beta, minusbeta, continuousstim, weighted, norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### batch simulation (multiprocessed - from cli)\n",
    "- running directly from the cli continuously updates mp progress bar\n",
    "- specifying parameters \n",
    "    - single value 'x'\n",
    "    - a comma separated list 'x,y,z' \n",
    "    - slice '[0.0:1.01:0.02]' ~ (start,end,stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cmd = f\"cd .. && python mp_run.py --sim eif_attr_stim --path {os.path.join(base_path, 'cli')} --simtime {simtime} --perturbation [0.0:0.205:0.1] --norm {norm} --weighted {weighted}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# res, err = utils.run_cmd(cmd)\n",
    "# print(res)\n",
    "# if len(err) > 0:\n",
    "#     print(err)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## analyzing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_start = 200.0\n",
    "t_end = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### general analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze(path, t_start, t_end):\n",
    "    with persistence.FileMap(path, mode=\"read\") as data:\n",
    "        analyzer = ExperimentAnalysis.ExperimentAnalysis(\n",
    "            experiment_data=data, t_start=t_start, t_end=t_end\n",
    "        )\n",
    "        # oscillation\n",
    "        analyzer.analyze_instantaneous_rate()\n",
    "        analyzer.analyze_smoothed_rate(window_size=1.0)\n",
    "        analyzer.analyze_peaks()\n",
    "        analyzer.analyze_cell_rate()\n",
    "        analyzer.analyze_power_spectral_density(separate_intervals=True)\n",
    "        analyzer.analyze_synchronization_frequency()\n",
    "        # analyzer.analyze_total_synaptic_conductance(pop_e=\"E\", pop_i=\"I\")\n",
    "\n",
    "        # attractor\n",
    "\n",
    "        analyzer.analyze_snapshots(pop_name=\"E\")\n",
    "        analyzer.analyze_similarity_distribution(pop_name=\"E\")\n",
    "\n",
    "        sparsity = data[\"persist_data\"][\"E\"][\"sparsity\"]\n",
    "        pattern = data[\"persist_data\"][\"E\"][\"pattern\"]\n",
    "\n",
    "        analysis = analyzer.report\n",
    "\n",
    "        dt = data[\"meta\"][\"dt\"][\"value\"] * 1000\n",
    "        t = data[\"meta\"][\"t\"][\"value\"] * 1000\n",
    "        t_start, t_end, t_last = utils.compute_time_interval(t, dt, t_start, t_end)\n",
    "\n",
    "        stimulus_pattern = data[\"persist_data\"][\"stimulus_block_interval\"][\n",
    "            \"stimulus_pattern\"\n",
    "        ]\n",
    "        # convert to ms\n",
    "        stimulus_block_interval = data[\"persist_data\"][\"stimulus_block_interval\"][\n",
    "            \"interval\"\n",
    "        ]\n",
    "        # treat homogeneous and inhomogeneous drive\n",
    "        if \"value\" in stimulus_block_interval.keys():\n",
    "            # homogeneous case\n",
    "            stimulus_block_interval = stimulus_block_interval[\"value\"] * 1000\n",
    "        else:\n",
    "            # inhomogeneous case load dictionary\n",
    "            stimulus_block_interval = stimulus_block_interval.load()\n",
    "\n",
    "        spike_train_e = data[\"SpikeDeviceGroup\"][\"E\"][\"spike\"][\"spike_train\"][\"value\"].load()\n",
    "        spike_train_i = data[\"SpikeDeviceGroup\"][\"I\"][\"spike\"][\"spike_train\"][\"value\"].load()\n",
    "\n",
    "\n",
    "        params = dict(mp.file_name_parser(fname))\n",
    "\n",
    "\n",
    "    sm_rate_e = analysis[\"SpikeDeviceGroup\"][\"E\"][\"smoothed_rate\"][\"value\"]\n",
    "    sm_rate_i = analysis[\"SpikeDeviceGroup\"][\"I\"][\"smoothed_rate\"][\"value\"]\n",
    "\n",
    "    troughs = analysis[\"SpikeDeviceGroup\"][\"E\"][\"peaks\"][\"mins\"]\n",
    "    peaks = analysis[\"SpikeDeviceGroup\"][\"E\"][\"peaks\"][\"maxs\"]\n",
    "\n",
    "    sync_freq = analysis[\"SpikeDeviceGroup\"][\"E\"][\"synchronization_frequency\"][\n",
    "        \"frequency\"\n",
    "    ][\"value\"]\n",
    "\n",
    "\n",
    "    snapshots = analysis[\"SpikeDeviceGroup\"][\"E\"][\"snapshots\"]\n",
    "    similarity_distribution = analysis[\"SpikeDeviceGroup\"][\"E\"][\"pattern\"][\n",
    "        \"similarity_distribution\"\n",
    "    ]\n",
    "\n",
    "    return t_start, t_end, dt, peaks, troughs, snapshots, similarity_distribution, stimulus_pattern, stimulus_block_interval, pattern, sync_freq, sm_rate_e, sm_rate_i, spike_train_e, spike_train_i, params, analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_start, t_end, dt, peaks, troughs, snapshots, similarity_distribution, stimulus_pattern, stimulus_block_interval, pattern, sync_freq, pop_rate_e, pop_rate_i, spike_train_e, spike_train_i, params, analysis_data = analyze(os.path.join(base_path_code, fname), t_start, t_end)\n",
    "t_startu, t_endu, dtu, peaksu, troughsu, snapshotsu, similarity_distributionu, stimulus_patternu, stimulus_block_intervalu, patternu, sync_frequ, pop_rate_eu, pop_rate_iu, spike_train_eu, spike_train_iu, paramsu, analysis_datau = analyze(os.path.join(base_path_code, fnameu), t_start, t_end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### analysis of pvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute pvalues for the stimulus pattern\n",
    "\n",
    "def compute_pvals(snapshots,similarity_distribution, stimulus_pattern, stimuluspatternidx):\n",
    "    # snapshots (C x pattern_length) where C num snapshots\n",
    "    pattern_length = snapshots.shape[1]\n",
    "    num_patterns = similarity_distribution.shape[0]\n",
    "    num_spikes_per_snapshot = np.sum(snapshots, axis=1)\n",
    "            \n",
    "    # print(similarity_distribution.shape)\n",
    "    similarity = similarity_distribution[stimuluspatternidx].ravel()\n",
    "\n",
    "\n",
    "    number_ones = np.sum(stimulus_pattern)\n",
    "    pattern_length = stimulus_pattern.size\n",
    "\n",
    "    pvalues = np.zeros_like(similarity, dtype=float)\n",
    "    for i in tqdm.tqdm(range(similarity.size)):\n",
    "        p = num_spikes_per_snapshot[i] / pattern_length\n",
    "        pval = attractor.pvalue_snapshot(pattern_length, number_ones, similarity[i], p)\n",
    "        pvalues[i] = pval\n",
    "    \n",
    "    return pvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = np.zeros_like(np.arange(20))\n",
    "# x[3] = 2\n",
    "# print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pvals = compute_pvals(snapshots, similarity_distribution, stimulus_pattern, stimuluspatternidx)\n",
    "pvalsu = compute_pvals(snapshotsu, similarity_distributionu, stimulus_pattern, stimuluspatternidx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plot\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plotting oscillation dynamics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_osc(path, analysis_data, t_start):\n",
    "    with persistence.FileMap(path, mode=\"read\") as data:\n",
    "        plotter = plot.ExperimentPlotter(data=data, analysis=analysis_data, figsize=(20,10), t_start=t_start, pop_name_e=\"E\", pop_name_i=\"I\")\n",
    "\n",
    "        plotter.plot_spike_train()\n",
    "        # plotter.plot_voltage()\n",
    "        plotter.plot_instantaneous_rate(pop_name=[\"E\", \"I\"])\n",
    "        plotter.plot_smoothed_rate(pop_name=[\"E\"])\n",
    "        plotter.plot_smoothed_rate(pop_name=[\"I\"])\n",
    "\n",
    "        plotter.draw()\n",
    "\n",
    "        plotter.show()\n",
    "\n",
    "\n",
    "        plotter = plot.ExperimentPlotter(data=data, analysis=analysis_data, figsize=(20,10), sharex=True, t_start=100, pop_name_e=\"E\", pop_name_i=\"I\")\n",
    "        plotter.plot_power_spectrum(pop_name=\"E\")\n",
    "        plotter.plot_power_spectrum(pop_name=\"I\")\n",
    "\n",
    "        plotter.draw()\n",
    "        plotter.show()\n",
    "\n",
    "\n",
    "\n",
    "        plotter = plot.ExperimentPlotter(data=data, analysis=analysis_data, figsize=(20,10), sharex=True, t_start=100, pop_name_e=\"E\", pop_name_i=\"I\")\n",
    "        plotter.plot_power_spectogram_over_time(pop_name=\"E\")\n",
    "        plotter.plot_power_spectogram_over_time(pop_name=\"I\")\n",
    "        plotter.draw()\n",
    "        plotter.show()\n",
    "\n",
    "        plotter = plot.ExperimentPlotter(data=data, analysis=analysis_data, figsize=(20,10), sharex=True, t_start=100, pop_name_e=\"E\", pop_name_i=\"I\")\n",
    "        plotter.plot_cell_rate(pop_name=\"E\")\n",
    "        plotter.plot_cell_rate(pop_name=\"I\")\n",
    "        plotter.draw()\n",
    "        plotter.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Oscillation plot {fname}\")\n",
    "plot_osc(os.path.join(base_path_code, fname), analysis_data, t_start)\n",
    "print(f\"Oscillation plot {fnameu}\")\n",
    "plot_osc(os.path.join(base_path_code, fname), analysis_datau, t_start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plot attractor dynamics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def base_name_from_path(path: str):\n",
    "    return os.path.split(path)[1]\n",
    "\n",
    "# parameters with u are simply parameters corresponding to the unweighted sim\n",
    "def plot_similarity_blocked_stimulus_sliding_window_delta(\n",
    "    t_start, \n",
    "    dt,\n",
    "    t_end,\n",
    "    pattern, \n",
    "    stimulus_pattern,\n",
    "    stimulus_block_interval,\n",
    "    similarity_distribution,\n",
    "    similarity_distributionu,\n",
    "    pvals,\n",
    "    pvalsu,\n",
    "    params, \n",
    "    peaks, \n",
    "    peaksu,\n",
    "    troughs, \n",
    "    troughsu,\n",
    "    sync_freq, \n",
    "\n",
    "    \n",
    "):\n",
    "    \"\"\"\n",
    "    :param pvals: pvalues (C,) weighted pvalues for stimulus_pattern\n",
    "    :param pvalsu: pvalues (C,) unweighted pvalues for stimulus_pattern \n",
    "    :param peaks: indices of the peaks at simulation time step dt resolution\n",
    "    :param troughs: indices of the troughs at simulation time step dt resolution\n",
    "    \"\"\"\n",
    "\n",
    "    time = np.arange(t_start, t_end + dt, dt)\n",
    "\n",
    "    stimulus_onset = stimulus_block_interval[:, 0]\n",
    "\n",
    "    stimulus_length = stimulus_block_interval[:, 1] - stimulus_block_interval[:, 0]\n",
    "\n",
    "    stimulus_length = stimulus_length[0]\n",
    "\n",
    "    #time = np.arange(t_start, t_end + dt, dt)\n",
    "\n",
    "\n",
    "    # parameters\n",
    "    significance = 0.05\n",
    "    window_length = 20.0  # stimulus_length\n",
    "    # resolution at 0.1 ms\n",
    "    window_step = 0.1\n",
    "    first_stim_onset = stimulus_onset[0]\n",
    "    if stimulus_onset.size < 2 or not np.allclose(\n",
    "        stimulus_onset[1:] - stimulus_onset[0:-1], stimulus_onset[1] - stimulus_onset[0]\n",
    "    ):\n",
    "        raise ValueError(\n",
    "            \"a constant stimulus_onset_interval required between onsets of the stimulus and\"\n",
    "            + \" at least two stimulus presentations. \"\n",
    "            + f\"Length of stimulus_presentations {stimulus_onset.size} and stimulus_onset_intervals {stimulus_onset[1:] - stimulus_onset[0:-1]}.\"\n",
    "        )\n",
    "\n",
    "    inter_onset_interval = stimulus_onset[1] - stimulus_onset[0]\n",
    "\n",
    "\n",
    "    # as only pvalues for stimulus pattern are computed here - just reuse for all patterns and ignore\n",
    "    pvals_expanded = np.tile(pvals, pattern.shape[0]).reshape(pattern.shape[0],-1)\n",
    "    pvalsu_expanded = np.tile(pvalsu, pattern.shape[0]).reshape(pattern.shape[0],-1)\n",
    "\n",
    "    assert np.all(pvals_expanded[0] == pvals)\n",
    "    # weighted snaps\n",
    "\n",
    "\n",
    "\n",
    "    indices = attractor.indices_snapshots_blocked_stimulus_sliding_window(\n",
    "        pvals_expanded,\n",
    "        stimulus_pattern,\n",
    "        pattern,\n",
    "        time[troughs],\n",
    "        time[peaks],\n",
    "        first_stim_onset,\n",
    "        t_end,\n",
    "        inter_onset_interval,\n",
    "        window_length,\n",
    "        window_step,\n",
    "    )\n",
    "    pvalue = [np.hstack([pvals_expanded[ix] for ix in idx]) for idx in indices]\n",
    "\n",
    "    #print([p.shape for p in pvalue])\n",
    "\n",
    "    sims = [np.hstack([similarity_distribution[ix] for ix in idx]) for idx in indices]\n",
    "\n",
    "    # use sims now that we have them\n",
    "    (sign_snaps, snap_pvals) = tuple(\n",
    "        zip(\n",
    "            *[\n",
    "                (np.sum(pv <= significance) / pv.size, pv)\n",
    "                if pv.size > 0\n",
    "                else (0.0, np.ndarray([]))\n",
    "                for pv in pvalue\n",
    "            ]\n",
    "        )\n",
    "    )\n",
    "\n",
    "    \n",
    "    # print(\"sign_snaps:\\n\",sign_snaps)\n",
    "    # print(\"snap_pvals:\\n\",snap_pvals)\n",
    "    mean_pvals = np.array([np.mean(sp) for sp in snap_pvals])\n",
    "    sign_snaps = np.array(sign_snaps)\n",
    "    mean_sims = np.array([np.mean(sm) for sm in sims])\n",
    "\n",
    "    # unwieghted snaps\n",
    "    indices = attractor.indices_snapshots_blocked_stimulus_sliding_window(\n",
    "        pvalsu_expanded,\n",
    "        stimulus_pattern,\n",
    "        pattern,\n",
    "        time[troughsu],\n",
    "        time[peaksu],\n",
    "        first_stim_onset,\n",
    "        t_end,\n",
    "        inter_onset_interval,\n",
    "        window_length,\n",
    "        window_step,\n",
    "    )\n",
    "    pvalue_unweighted = [\n",
    "        np.hstack([pvalsu_expanded[ix] for ix in idx]) for idx in indices\n",
    "    ]\n",
    "\n",
    "    # use sims now that we have them\n",
    "    (sign_snaps_unweighted, snap_pvals_unweighted) = tuple(\n",
    "        zip(\n",
    "            *[\n",
    "                (np.sum(pv <= significance) / pv.size, pv)\n",
    "                if pv.size > 0\n",
    "                else (0.0, np.ndarray([]))\n",
    "                for pv in pvalue_unweighted\n",
    "            ]\n",
    "        )\n",
    "    )\n",
    "    sims_unweighted = [\n",
    "        np.hstack([similarity_distributionu[ix] for ix in idx])\n",
    "        for idx in indices\n",
    "    ]\n",
    "    mean_pvals_unweighted = np.array([np.mean(sp) for sp in snap_pvals_unweighted])\n",
    "    sign_snaps_unweighted = np.array(sign_snaps_unweighted)\n",
    "    mean_sims_unweighted = np.array([np.mean(sm) for sm in sims_unweighted])\n",
    "    fig, ax = plt.subplots(2, 1, figsize=(10, 10))\n",
    "\n",
    "    ttl = \" | \".join([f\"{p}: {v}\" for p, v in params.items()])\n",
    "\n",
    "    pop_name = \"E\"\n",
    "\n",
    "    # one exemplary stimulus_onset , eg the second one - first pot not suitable as t_start may coincide with onset, for plotting\n",
    "    example_onset = stimulus_onset[1]\n",
    "    for i, zoomed in enumerate([False, True]):\n",
    "        plot.plot_similarity_blocked_stimulus_sliding_window_delta(\n",
    "            fig,\n",
    "            ax[i],\n",
    "            example_onset,\n",
    "            inter_onset_interval,\n",
    "            stimulus_length,\n",
    "            window_step,\n",
    "            sign_snaps=sign_snaps,\n",
    "            mean_pvals=mean_pvals,\n",
    "            mean_similarity=mean_sims,\n",
    "            sign_snaps_unweighted=sign_snaps_unweighted,\n",
    "            mean_pvals_unweighted=mean_pvals_unweighted,\n",
    "            mean_similarity_unweighted=mean_sims_unweighted,\n",
    "            zoomed=zoomed,\n",
    "        )\n",
    "    ax[0].set_title(\n",
    "        f\"similarity per pattern {pop_name} Sync Freq. {sync_freq:.2f} {ttl}\",\n",
    "        wrap=True,\n",
    "    )\n",
    "    return fig\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plot_similarity_blocked_stimulus_sliding_window_delta(\n",
    "    t_start, \n",
    "    dt,\n",
    "    t_end,\n",
    "    pattern, \n",
    "    stimulus_pattern,\n",
    "    stimulus_block_interval,\n",
    "    similarity_distribution,\n",
    "    similarity_distributionu,\n",
    "    pvals,\n",
    "    pvalsu,\n",
    "    params, \n",
    "    peaks, \n",
    "    peaksu,\n",
    "    troughs, \n",
    "    troughsu,\n",
    "    sync_freq, \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### plot psth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_psth(t_start, t_end, dt, stimulus_block_interval, stimulus_pattern, troughs, peaks, spike_train):\n",
    "\n",
    "    time = np.arange(t_start, t_end + dt, dt)\n",
    "\n",
    "    # spike train\n",
    "    num_spikes = sum([v.size for v in spike_train.values()])\n",
    "    spike_train_ids = np.zeros(num_spikes, dtype=int)\n",
    "    spike_train_times = np.zeros(num_spikes, dtype=float)\n",
    "    offset = 0\n",
    "    for neuron, train in spike_train.items():\n",
    "        spike_train_ids[offset : offset + train.size] = int(neuron)\n",
    "        # in [ms]\n",
    "        spike_train_times[offset : offset + train.size] = train * 1000\n",
    "\n",
    "        offset += train.size\n",
    "\n",
    "    (\n",
    "        stimulus_onset,\n",
    "        stimulus_end,\n",
    "        stimulus_length,\n",
    "        inter_presentation_interval,\n",
    "    ) = analysis.compute_stimulus_characteristics(stimulus_block_interval)\n",
    "\n",
    "    # curtail troughs, peaks and time to complete presentation cycles\n",
    "    troughs = troughs[time[troughs] <= stimulus_end[-1]]\n",
    "    peaks = peaks[time[peaks] <= stimulus_end[-1]]\n",
    "    time = time[time <= stimulus_end[-1]]\n",
    "\n",
    "    # separate snapshots into troughs, peaks, stimulus\n",
    "    (\n",
    "        trough_cycle_idx,\n",
    "        peak_cycle_idx,\n",
    "    ) = attractor.separate_presentation_cycles(\n",
    "        time[troughs],\n",
    "        time[peaks],\n",
    "        stimulus_onset,\n",
    "    )\n",
    "\n",
    "    # presentation cycle times\n",
    "    first_stim_onset = stimulus_onset[0]\n",
    "    pres_beg, pres_end = attractor.resolve_time_interval(\n",
    "        stimulus_onset, inter_presentation_interval, stimulus_length\n",
    "    )\n",
    "\n",
    "    # troughs\n",
    "    # ith entry ~ trough_cycle_idx[i] and encompasses spikes relevant for stimulus_onset[i]\n",
    "    spike_train_trough_idx = [\n",
    "        np.logical_and(\n",
    "            spike_train_times >= pres_beg[idx],\n",
    "            spike_train_times < pres_end[idx],\n",
    "        )\n",
    "        for idx in trough_cycle_idx\n",
    "    ]\n",
    "    resolved_spike_times_trough = [\n",
    "        spike_train_times[idx] - stimulus_onset[trough_cycle_idx[i]]\n",
    "        for i, idx in enumerate(spike_train_trough_idx)\n",
    "    ]\n",
    "    spike_train_ids_trough = [\n",
    "        spike_train_ids[idx] for idx in spike_train_trough_idx\n",
    "    ]\n",
    "\n",
    "    # peaks\n",
    "    spike_train_peak_idx = [\n",
    "        np.logical_and(\n",
    "            spike_train_times >= pres_beg[idx],\n",
    "            spike_train_times < pres_end[idx],\n",
    "        )\n",
    "        for idx in np.nonzero(peak_cycle_idx)[0]\n",
    "    ]\n",
    "    resolved_spike_times_peak = [\n",
    "        spike_train_times[idx] - stimulus_onset[peak_cycle_idx[i]]\n",
    "        for i, idx in enumerate(spike_train_peak_idx)\n",
    "    ]\n",
    "    spike_train_ids_peak = [\n",
    "        spike_train_ids[idx] for idx in spike_train_peak_idx\n",
    "    ]\n",
    "\n",
    "    fig, ax = plt.subplots(2, 1, figsize=(20, 10), sharex=True)\n",
    "    plt.subplots_adjust(wspace=0, hspace=0)\n",
    "\n",
    "    for i, (spike_time, spike_id, num_presentations) in enumerate(\n",
    "        zip(\n",
    "            [resolved_spike_times_trough, resolved_spike_times_peak],\n",
    "            [spike_train_ids_trough, spike_train_ids_peak],\n",
    "            [len(spike_train_trough_idx), len(spike_train_peak_idx)],\n",
    "        )\n",
    "    ):\n",
    "        # print(type(spike_time))\n",
    "        if len(spike_time) > 0:\n",
    "            plot.psth(\n",
    "                fig,\n",
    "                ax[i],\n",
    "                np.hstack(spike_time),\n",
    "                np.hstack(spike_id),\n",
    "                stimulus_pattern,\n",
    "                num_presentations,\n",
    "                inter_presentation_interval,\n",
    "                stimulus_length,\n",
    "                num_bins=48,\n",
    "            )\n",
    "\n",
    "    ax[0].set_title(\n",
    "        f\"psth for presentation cycles trough (top, # cycles {trough_cycle_idx.size}) and peak (bottom, # cycles {peak_cycle_idx.size})\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with persistence.FileMap(os.path.join(base_path_code, fname)) as fl:\n",
    "    spike_train = fl[\"SpikeDeviceGroup\"][\"E\"][\"spike\"][\"spike_train\"][\n",
    "        \"value\"\n",
    "    ].load()\n",
    "\n",
    "with persistence.FileMap(os.path.join(base_path_code, fnameu)) as fl:\n",
    "    spike_trainu = fl[\"SpikeDeviceGroup\"][\"E\"][\"spike\"][\"spike_train\"][\n",
    "        \"value\"\n",
    "    ].load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fname)\n",
    "plot_psth(t_start, t_end, dt, stimulus_block_interval, stimulus_pattern, troughs, peaks, spike_train)\n",
    "print(fnameu)\n",
    "plot_psth(t_start, t_end, dt, stimulus_block_interval, stimulus_pattern, troughsu, peaksu, spike_trainu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### spike presentation cycles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_spike_presentation_cycle(t_start, t_end, dt, spike_train_e, spike_train_i, pop_rate_e, pop_rate_i, stimulus_block_interval, stimulus_pattern, peaks, troughs):\n",
    "    fig, ax = plt.subplots(4, 1, figsize=(20, 10))\n",
    "    plt.subplots_adjust(hspace=0.35)\n",
    "\n",
    "    time = np.arange(t_start, t_end + dt, dt)\n",
    "\n",
    "    for pop_i, (spike_train, pop_rate, pn) in enumerate(\n",
    "        zip(\n",
    "            [spike_train_e, spike_train_i],\n",
    "            [pop_rate_e, pop_rate_i],\n",
    "            [\"E\", \"I\"],\n",
    "        )\n",
    "    ):\n",
    "\n",
    "        num_spikes = sum([v.size for v in spike_train.values()])\n",
    "        spike_train_ids = np.zeros(num_spikes, dtype=int)\n",
    "        spike_train_times = np.zeros(num_spikes, dtype=float)\n",
    "        offset = 0\n",
    "        for neuron, train in spike_train.items():\n",
    "            spike_train_ids[offset : offset + train.size] = int(neuron)\n",
    "            # in [ms]\n",
    "            spike_train_times[offset : offset + train.size] = train * 1000\n",
    "\n",
    "            offset += train.size\n",
    "\n",
    "        (\n",
    "            stimulus_onset,\n",
    "            stimulus_end,\n",
    "            stimulus_length,\n",
    "            inter_presentation_interval,\n",
    "        ) = analysis.compute_stimulus_characteristics(\n",
    "            stimulus_block_interval\n",
    "        )\n",
    "\n",
    "        # separate snapshots into troughs, peaks, stimulus\n",
    "        (\n",
    "            trough_cycle_idx,\n",
    "            peak_cycle_idx,\n",
    "        ) = attractor.separate_presentation_cycles(\n",
    "            time[troughs],\n",
    "            time[peaks],\n",
    "            stimulus_onset,\n",
    "        )\n",
    "\n",
    "        cycles = [trough_cycle_idx, peak_cycle_idx]\n",
    "        for i, idx in enumerate(cycles):\n",
    "                            if idx.size > 0:\n",
    "                                plot.plot_spike_train_presentation_cycle(\n",
    "                                    fig,\n",
    "                                    ax[pop_i * len(cycles) + i],\n",
    "                                    spike_train_ids,\n",
    "                                    spike_train_times,\n",
    "                                    stimulus_onset[idx][1 if idx.size > 1 else 0],\n",
    "                                    inter_presentation_interval,\n",
    "                                    stimulus_length,\n",
    "                                    pop_rate,\n",
    "                                    t_start,\n",
    "                                    t_end,\n",
    "                                    dt,\n",
    "                                    stimulus_pattern=stimulus_pattern\n",
    "                                    if pn == \"E\"\n",
    "                                    else None,\n",
    "                                )\n",
    "\n",
    "    ax[0].set_title(\n",
    "        f\"spikes during a presentation cycle: E group trough, E group peak, I group trough, I group peak (top to bottom)\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fname)\n",
    "plot_spike_presentation_cycle(t_start, t_end, dt, spike_train_e, spike_train_i, pop_rate_e, pop_rate_i, stimulus_block_interval, stimulus_pattern, peaks, troughs)\n",
    "print(fnameu)\n",
    "plot_spike_presentation_cycle(t_start, t_end, dt, spike_train_eu, spike_train_iu, pop_rate_eu, pop_rate_iu, stimulus_block_interval, stimulus_pattern, peaksu, troughsu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with persistence.FileMap(os.path.join(base_path_code, fname)) as data:\n",
    "    scale = data[\"Synapse\"][\"S_E_E\"][\"synapse_params\"][\"scale\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_scale(scale):\n",
    "    vals, counts = np.unique(scale, return_counts=True)\n",
    "\n",
    "    fig, ax = plt.subplots(1, 1)\n",
    "    ax.scatter(vals, np.log(counts))\n",
    "    ax.set_xlabel(\"synaptic input scale\")\n",
    "    ax.set_ylabel(\"log count\")\n",
    "    ax.set_title(\"Synaptic input scale matrix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_scale(scale)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ebe64fecbd0eef7c033eaaa744c03b8773bb4ec3a008ba4e6ceb9264c2f535b6"
  },
  "kernelspec": {
   "display_name": "Python (attractor)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
